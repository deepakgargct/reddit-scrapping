{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9L4jDhdXK2SnzfwKW2Sgu"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p6QgnMgG9Wm",
        "outputId": "afca2fa0-d0b7-4b01-991e-5055e36bc4ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting praw\n",
            "  Downloading praw-7.8.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting prawcore<3,>=2.4 (from praw)\n",
            "  Downloading prawcore-2.4.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting update_checker>=0.18 (from praw)\n",
            "  Downloading update_checker-0.18.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.11/dist-packages (from praw) (1.8.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from prawcore<3,>=2.4->praw) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2025.1.31)\n",
            "Downloading praw-7.8.1-py3-none-any.whl (189 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.3/189.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prawcore-2.4.0-py3-none-any.whl (17 kB)\n",
            "Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
            "Installing collected packages: update_checker, prawcore, praw\n",
            "Successfully installed praw-7.8.1 prawcore-2.4.0 update_checker-0.18.0\n",
            "Enter keywords to search (comma-separated): botox\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for: botox...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping complete! Data saved as 'reddit_posts_cleaned.csv'.\n"
          ]
        }
      ],
      "source": [
        "# Install required library\n",
        "!pip install praw\n",
        "\n",
        "# Import necessary libraries\n",
        "import praw\n",
        "import pandas as pd\n",
        "import re\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Initialize Reddit instance\n",
        "reddit = praw.Reddit(client_id=\"3fXfFslCainOY6xM4Zm0Ng\",\n",
        "                     client_secret=\"1Zxte6SguEhBrtYAJirOBI7kbwV3yQ\",\n",
        "                     user_agent=\"name\")\n",
        "\n",
        "# Ask user for keywords to search\n",
        "keywords = input(\"Enter keywords to search (comma-separated): \").split(',')\n",
        "\n",
        "# Define list to store post data\n",
        "data = []\n",
        "\n",
        "# Get the timestamp for 6 months ago\n",
        "six_months_ago = datetime.utcnow() - timedelta(days=180)\n",
        "six_months_timestamp = int(six_months_ago.timestamp())\n",
        "\n",
        "# Function to clean post text (remove external links & excessive whitespace)\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove excessive whitespace\n",
        "    return text\n",
        "\n",
        "# Function to check if the URL is a Reddit link\n",
        "def filter_reddit_links(url):\n",
        "    return url if \"reddit.com\" in url else \"N/A\"\n",
        "\n",
        "# Search Reddit for keyword-matching posts (past year, then filter)\n",
        "for keyword in keywords:\n",
        "    keyword = keyword.strip()\n",
        "    print(f\"Searching for: {keyword}...\")\n",
        "\n",
        "    # Fetch posts from past year\n",
        "    for post in reddit.subreddit(\"all\").search(keyword, sort=\"top\", time_filter=\"year\", limit=200):\n",
        "\n",
        "        # Filter posts from last 6 months\n",
        "        if post.created_utc >= six_months_timestamp:\n",
        "            data.append({\n",
        "                'Post ID': post.id,\n",
        "                'Title': post.title.strip(),\n",
        "                'Author': post.author.name if post.author else 'Unknown',\n",
        "                'Timestamp': pd.to_datetime(post.created_utc, unit='s'),\n",
        "                'Text': clean_text(post.selftext),  # Cleaned text (no links)\n",
        "                'Score': post.score,\n",
        "                'Total Comments': post.num_comments,\n",
        "                'Post URL': filter_reddit_links(post.url)  # Keep only Reddit URLs\n",
        "            })\n",
        "\n",
        "# Convert to pandas DataFrame\n",
        "reddit_posts = pd.DataFrame(data)\n",
        "\n",
        "# Save to CSV with proper formatting\n",
        "reddit_posts.to_csv(\"reddit_posts_cleaned.csv\", index=False, encoding='utf-8')\n",
        "\n",
        "print(\"Scraping complete! Data saved as 'reddit_posts_cleaned.csv'.\")\n"
      ]
    }
  ]
}